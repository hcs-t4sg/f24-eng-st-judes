{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmSRve_3qDBA",
        "outputId": "cb5ce72c-cdb7-4a42-ae04-b1b6aab39520"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x7cc9ee50e470>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvpFV9wMgWdt",
        "outputId": "bc030ed5-5b74-480d-aefd-f0e2a914a8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1_keywords_frame = pd.read_csv(\"/content/drive/MyDrive/T4SG St Jude/Asset CSVs/L1Groupings.csv\")\n",
        "\n",
        "n = 61\n",
        "img_name = l1_keywords_frame.iloc[n, 1]\n",
        "keywords = l1_keywords_frame.iloc[n, 3]\n",
        "\n",
        "print('Image name: {}'.format(img_name))\n",
        "print(keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBLTZ-TBqddx",
        "outputId": "b75bd219-93b6-4f23-d36e-e2211cd83f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image name: 10002670-124-V1_TIF.jpg\n",
            "Campus, Decorations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Level1KeywordsDataset(Dataset):\n",
        "    \"\"\"Keywords dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.keywords_frame = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keywords_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.keywords_frame.iloc[idx, 1])\n",
        "        image = io.imread(img_name)\n",
        "        keywords = self.keywords_frame.iloc[idx, 3].split(\", \")\n",
        "        keyword_map = {'People': 0,\n",
        "                       'Drone - Aerial': 1,\n",
        "                       'Campus': 2,\n",
        "                       'Science': 3,\n",
        "                       'Labs': 4,\n",
        "                       'Memphis': 5,\n",
        "                       'Events': 6,\n",
        "                       'Decorations': 7,\n",
        "                       'St Jude Research Website': 8,\n",
        "                       'Clinical': 9,\n",
        "                       'Board of Governors': 10,\n",
        "                       'Convocation': 11,\n",
        "                       'Covid': 12,\n",
        "                       'ALSAC': 13}\n",
        "        keywords_arr = np.zeros(14, dtype=float)\n",
        "        for i in keywords:\n",
        "            if i in keyword_map.keys():\n",
        "                keywords_arr[keyword_map[i]] = 1\n",
        "        keywords = keywords_arr\n",
        "        sample = {'image': image, 'keywords': keywords}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "_OF4Ho4UrYd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "\n",
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, keywords = sample['image'], sample['keywords']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        img = skimage.transform.resize(image, (new_h, new_w))\n",
        "\n",
        "        # h and w are swapped for keywords because for images,\n",
        "        # x and y axes are axis 1 and 0 respectively\n",
        "\n",
        "        return {'image': img, 'keywords': keywords}\n",
        "\n",
        "\n",
        "class RandomCrop(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, square crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = (output_size, output_size)\n",
        "        else:\n",
        "            assert len(output_size) == 2\n",
        "            self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, keywords = sample['image'], sample['keywords']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        new_h, new_w = self.output_size\n",
        "\n",
        "        top = np.random.randint(0, h - new_h + 1)\n",
        "        left = np.random.randint(0, w - new_w + 1)\n",
        "\n",
        "        image = image[top: top + new_h,\n",
        "                      left: left + new_w]\n",
        "\n",
        "        return {'image': image, 'keywords': keywords}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, keywords = sample['image'], sample['keywords']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C x H x W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        # keywords = keywords.split(\", \")\n",
        "        # for i in range(len(keywords)):\n",
        "        #     keywords[i] = keyword_map[i]\n",
        "        # keywords = np.array(keywords)\n",
        "        # print(image.size)\n",
        "        return {'image': torch.from_numpy(image),\n",
        "                'keywords': torch.from_numpy(keywords)}"
      ],
      "metadata": {
        "id": "yX4iPkEOsTa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    Rescale((256, 256)),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "batch_size = 1\n",
        "root_dir = \"/content/drive/MyDrive/T4SG St Jude/Labelled Assets\"\n",
        "csv_file = \"/content/drive/MyDrive/T4SG St Jude/Asset CSVs/L1Groupings.csv\"\n",
        "test_file = \"/content/drive/MyDrive/T4SG St Jude/Asset CSVs/L1GroupingsPart5.csv\"\n",
        "\n",
        "trainset = Level1KeywordsDataset(csv_file=csv_file,\n",
        "                                 root_dir=root_dir,\n",
        "                                 transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)\n",
        "\n",
        "testset = Level1KeywordsDataset(csv_file=test_file,\n",
        "                                 root_dir=root_dir,\n",
        "                                 transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=0)\n",
        "\n",
        "classes = ('People', 'Drone - Aerial', 'Campus', 'Science', 'Labs', 'Memphis',\n",
        "           'Events','Decorations','St Jude Research Website','Clinical',\n",
        "           'Board of Governors','Convocation','Covid','ALSAC')"
      ],
      "metadata": {
        "id": "0cDlBxOEyx1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(61 * 61 * 16, 256) # Initial Layer\n",
        "        self.fc2 = nn.Linear(256, 512) # Increase # of neurons: more things to learn\n",
        "        # self.fc3 = nn.Linear(512, 1024) # Optional (paired w/ below) (MODEL PERFORMS BETTER WITHOUT IT)\n",
        "        # self.fc4 = nn.Linear(1024, 512) # Optional (paired w/ above) (MODEL PERFORMS BETTER WITHOUT IT)\n",
        "        self.fc5 = nn.Linear(512, 256) # Decrease to converge to image\n",
        "        self.fc6 = nn.Linear(256, 128)\n",
        "        self.fc7 = nn.Linear(128, 14)\n",
        "        self.double() # Needed otherwise the types break\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # x = F.relu(self.fc3(x))\n",
        "        # x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = F.relu(self.fc6(x))\n",
        "        x = self.fc7(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "mRzLiOw03r3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)"
      ],
      "metadata": {
        "id": "GVAP4JZu312d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data['image'], data['keywords']\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 19:    # print every 20 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIPDqjvT38wn",
        "outputId": "d46f68d7-870c-40f0-b346-0d7f8d40b4b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    20] loss: 0.367\n",
            "[1,    40] loss: 0.285\n",
            "[1,    60] loss: 0.342\n",
            "[1,    80] loss: 0.311\n",
            "[1,   100] loss: 0.306\n",
            "[1,   120] loss: 0.296\n",
            "[1,   140] loss: 0.372\n",
            "[1,   160] loss: 0.266\n",
            "[2,    20] loss: 0.447\n",
            "[2,    40] loss: 0.267\n",
            "[2,    60] loss: 0.260\n",
            "[2,    80] loss: 0.348\n",
            "[2,   100] loss: 0.283\n",
            "[2,   120] loss: 0.368\n",
            "[2,   140] loss: 0.352\n",
            "[2,   160] loss: 0.274\n",
            "[3,    20] loss: 0.305\n",
            "[3,    40] loss: 0.217\n",
            "[3,    60] loss: 0.367\n",
            "[3,    80] loss: 0.260\n",
            "[3,   100] loss: 0.256\n",
            "[3,   120] loss: 0.324\n",
            "[3,   140] loss: 0.368\n",
            "[3,   160] loss: 0.395\n",
            "[4,    20] loss: 0.323\n",
            "[4,    40] loss: 0.250\n",
            "[4,    60] loss: 0.347\n",
            "[4,    80] loss: 0.348\n",
            "[4,   100] loss: 0.279\n",
            "[4,   120] loss: 0.331\n",
            "[4,   140] loss: 0.309\n",
            "[4,   160] loss: 0.341\n",
            "[5,    20] loss: 0.327\n",
            "[5,    40] loss: 0.329\n",
            "[5,    60] loss: 0.358\n",
            "[5,    80] loss: 0.297\n",
            "[5,   100] loss: 0.325\n",
            "[5,   120] loss: 0.294\n",
            "[5,   140] loss: 0.275\n",
            "[5,   160] loss: 0.356\n",
            "[6,    20] loss: 0.351\n",
            "[6,    40] loss: 0.305\n",
            "[6,    60] loss: 0.340\n",
            "[6,    80] loss: 0.249\n",
            "[6,   100] loss: 0.308\n",
            "[6,   120] loss: 0.297\n",
            "[6,   140] loss: 0.358\n",
            "[6,   160] loss: 0.379\n",
            "[7,    20] loss: 0.362\n",
            "[7,    40] loss: 0.290\n",
            "[7,    60] loss: 0.281\n",
            "[7,    80] loss: 0.299\n",
            "[7,   100] loss: 0.372\n",
            "[7,   120] loss: 0.286\n",
            "[7,   140] loss: 0.308\n",
            "[7,   160] loss: 0.338\n",
            "[8,    20] loss: 0.288\n",
            "[8,    40] loss: 0.276\n",
            "[8,    60] loss: 0.472\n",
            "[8,    80] loss: 0.287\n",
            "[8,   100] loss: 0.325\n",
            "[8,   120] loss: 0.288\n",
            "[8,   140] loss: 0.298\n",
            "[8,   160] loss: 0.329\n",
            "[9,    20] loss: 0.315\n",
            "[9,    40] loss: 0.296\n",
            "[9,    60] loss: 0.362\n",
            "[9,    80] loss: 0.319\n",
            "[9,   100] loss: 0.355\n",
            "[9,   120] loss: 0.284\n",
            "[9,   140] loss: 0.315\n",
            "[9,   160] loss: 0.306\n",
            "[10,    20] loss: 0.318\n",
            "[10,    40] loss: 0.357\n",
            "[10,    60] loss: 0.292\n",
            "[10,    80] loss: 0.301\n",
            "[10,   100] loss: 0.287\n",
            "[10,   120] loss: 0.326\n",
            "[10,   140] loss: 0.281\n",
            "[10,   160] loss: 0.343\n",
            "[11,    20] loss: 0.306\n",
            "[11,    40] loss: 0.317\n",
            "[11,    60] loss: 0.307\n",
            "[11,    80] loss: 0.323\n",
            "[11,   100] loss: 0.325\n",
            "[11,   120] loss: 0.302\n",
            "[11,   140] loss: 0.337\n",
            "[11,   160] loss: 0.249\n",
            "[12,    20] loss: 0.328\n",
            "[12,    40] loss: 0.407\n",
            "[12,    60] loss: 0.278\n",
            "[12,    80] loss: 0.312\n",
            "[12,   100] loss: 0.297\n",
            "[12,   120] loss: 0.289\n",
            "[12,   140] loss: 0.329\n",
            "[12,   160] loss: 0.334\n",
            "[13,    20] loss: 0.339\n",
            "[13,    40] loss: 0.294\n",
            "[13,    60] loss: 0.294\n",
            "[13,    80] loss: 0.334\n",
            "[13,   100] loss: 0.315\n",
            "[13,   120] loss: 0.270\n",
            "[13,   140] loss: 0.394\n",
            "[13,   160] loss: 0.280\n",
            "[14,    20] loss: 0.331\n",
            "[14,    40] loss: 0.326\n",
            "[14,    60] loss: 0.343\n",
            "[14,    80] loss: 0.306\n",
            "[14,   100] loss: 0.327\n",
            "[14,   120] loss: 0.300\n",
            "[14,   140] loss: 0.301\n",
            "[14,   160] loss: 0.263\n",
            "[15,    20] loss: 0.297\n",
            "[15,    40] loss: 0.272\n",
            "[15,    60] loss: 0.372\n",
            "[15,    80] loss: 0.246\n",
            "[15,   100] loss: 0.352\n",
            "[15,   120] loss: 0.291\n",
            "[15,   140] loss: 0.300\n",
            "[15,   160] loss: 0.377\n",
            "[16,    20] loss: 0.416\n",
            "[16,    40] loss: 0.254\n",
            "[16,    60] loss: 0.300\n",
            "[16,    80] loss: 0.326\n",
            "[16,   100] loss: 0.315\n",
            "[16,   120] loss: 0.340\n",
            "[16,   140] loss: 0.256\n",
            "[16,   160] loss: 0.311\n",
            "[17,    20] loss: 0.296\n",
            "[17,    40] loss: 0.321\n",
            "[17,    60] loss: 0.278\n",
            "[17,    80] loss: 0.253\n",
            "[17,   100] loss: 0.301\n",
            "[17,   120] loss: 0.378\n",
            "[17,   140] loss: 0.347\n",
            "[17,   160] loss: 0.327\n",
            "[18,    20] loss: 0.306\n",
            "[18,    40] loss: 0.329\n",
            "[18,    60] loss: 0.270\n",
            "[18,    80] loss: 0.232\n",
            "[18,   100] loss: 0.342\n",
            "[18,   120] loss: 0.345\n",
            "[18,   140] loss: 0.347\n",
            "[18,   160] loss: 0.355\n",
            "[19,    20] loss: 0.289\n",
            "[19,    40] loss: 0.371\n",
            "[19,    60] loss: 0.331\n",
            "[19,    80] loss: 0.309\n",
            "[19,   100] loss: 0.342\n",
            "[19,   120] loss: 0.277\n",
            "[19,   140] loss: 0.383\n",
            "[19,   160] loss: 0.286\n",
            "[20,    20] loss: 0.286\n",
            "[20,    40] loss: 0.330\n",
            "[20,    60] loss: 0.325\n",
            "[20,    80] loss: 0.346\n",
            "[20,   100] loss: 0.315\n",
            "[20,   120] loss: 0.312\n",
            "[20,   140] loss: 0.312\n",
            "[20,   160] loss: 0.362\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input(\"PROCEED IF YOU ARE VERY SURE YOU WANT TO SAVE A MODEL\")\n",
        "\n",
        "PATH = \"/content/drive/MyDrive/T4SG St Jude/20EpochTrainedClassifierv2.pth\"\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "KvnLI5Nmm8Pi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f7bccd-6d73-4dca-c04c-88c1142496df"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROCEED IF YOU ARE VERY SURE YOU WANT TO SAVE A MODEL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "Jzf2YC4nkicK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input(\"PROCEED IF YOU ARE VERY SURE YOU WANT TO LOAD A MODEL\")\n",
        "\n",
        "net = Net()\n",
        "PATH = \"/content/drive/MyDrive/T4SG St Jude/20EpochTrainedClassifier.pth\"\n",
        "net.load_state_dict(torch.load(PATH, weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nJZgMB8kfJG",
        "outputId": "15fb1813-4421-4e17-e91b-2270b79bcac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROCEED IF YOU ARE VERY SURE YOU WANT TO LOAD A MODEL\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)['image'], next(dataiter)['keywords']\n",
        "outputs = net(images)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4guKIMeiGY5",
        "outputId": "9a128dc5-b542-4b9a-a8ce-5137ba3da4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "print(classes[predicted[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnc6eHn-lmmg",
        "outputId": "132f1891-4a63-4c4b-feb7-90b49d873686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Campus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sum = 0\n",
        "control_sum = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data['image'], data['keywords']\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        # print(outputs)\n",
        "        predicted = outputs.flatten().numpy()\n",
        "        max_val = np.max(predicted)\n",
        "        min_val = np.min(predicted)\n",
        "        predicted = (predicted - min_val) / (max_val - min_val)\n",
        "        predicted = np.where(predicted >= 0.75, 1, 0)\n",
        "        predicted_keywords = [keyword for keyword in classes if predicted[classes.index(keyword)] == 1]\n",
        "        print(predicted_keywords)\n",
        "        labels = labels.flatten().numpy()\n",
        "        label_keywords = [keyword for keyword in classes if labels[classes.index(keyword)] == 1]\n",
        "        print(label_keywords)\n",
        "\n",
        "        cosine_similarity = np.dot(predicted, labels) / (np.linalg.norm(predicted) * np.linalg.norm(labels))\n",
        "        # print(cosine_similarity)\n",
        "        pred_sum += cosine_similarity\n",
        "        control_group = np.array([0,0,1,1,1,0,0,0,0,0,0,0,0,0]) # Campus, Science, Labs\n",
        "        control_similarity = np.dot(labels, control_group) / (np.linalg.norm(labels) * np.linalg.norm(control_group))\n",
        "        # print(control_similarity)\n",
        "        control_sum += control_similarity\n",
        "        # print(\"\\n\")\n",
        "        # print(labels)\n",
        "        # total += labels.size(0\n",
        "        # total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(pred_sum / len(testloader))\n",
        "print(control_sum / len(testloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjD1hSNXl5EH",
        "outputId": "d09a7095-1393-4efd-c6ea-b1ded21983d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Campus', 'Science', 'Labs']\n",
            "['People']\n",
            "['Campus']\n",
            "['Drone - Aerial', 'Campus']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['Science', 'Labs']\n",
            "['Campus']\n",
            "['People', 'Science', 'Labs']\n",
            "['Campus']\n",
            "['Campus', 'Labs']\n",
            "['Campus']\n",
            "['Drone - Aerial', 'Campus', 'Labs']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['Memphis']\n",
            "['Campus']\n",
            "['Drone - Aerial', 'Campus']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['People', 'Science', 'Labs']\n",
            "['Campus']\n",
            "['Memphis']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['People', 'Labs', 'St Jude Research Website']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['Science', 'Labs', 'St Jude Research Website']\n",
            "['Campus']\n",
            "['People', 'Science']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['Science', 'Labs', 'St Jude Research Website']\n",
            "['People', 'Campus', 'Science', 'Labs']\n",
            "['People', 'Science']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['People', 'Science', 'Labs']\n",
            "['Campus', 'Labs']\n",
            "['Memphis']\n",
            "['Campus']\n",
            "['Campus', 'ALSAC']\n",
            "['Campus']\n",
            "['People', 'Events', 'Convocation']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['Campus', 'Decorations']\n",
            "['People', 'Science', 'Labs']\n",
            "['People', 'Science', 'Labs']\n",
            "['Campus', 'Science', 'Labs']\n",
            "['Clinical']\n",
            "['People', 'Science', 'Labs']\n",
            "['Science', 'Labs']\n",
            "['Campus', 'Labs']\n",
            "['Science', 'Labs']\n",
            "0.44392190114340324\n",
            "0.4464781694372535\n"
          ]
        }
      ]
    }
  ]
}